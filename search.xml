<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SQL_互相关注的对数</title>
    <url>/2020/10/27/Sql-%E4%BA%92%E7%9B%B8%E5%85%B3%E6%B3%A8%E7%9A%84%E7%94%A8%E6%88%B7%E5%AF%B9%E6%95%B0/</url>
    <content><![CDATA[<p>表名：user_table</p>
<p>字段：user_id, follower_id</p>
<p>描述：该表统计了每个用户的id，以及其所关注的用户的id，求互相关注的用户的对数。</p>
<a id="more"></a>

<h2 id="（1）sql写法"><a href="#（1）sql写法" class="headerlink" title="（1）sql写法"></a>（1）sql写法</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(a.user_id)/<span class="number">2</span> following_pairs</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> t1.user_id,t1.follower_id</span><br><span class="line"><span class="keyword">FROM</span> user_table t1 <span class="keyword">JOIN</span> user_table t2</span><br><span class="line"><span class="keyword">ON</span> t1.user_id = t2.follower_id <span class="keyword">AND</span> t1.follower_id = t2.user_id) a</span><br></pre></td></tr></table></figure>

<h2 id="（2）思路及注意事项"><a href="#（2）思路及注意事项" class="headerlink" title="（2）思路及注意事项"></a>（2）思路及注意事项</h2><ol>
<li>最普适的方法是表联结，无论是给id还是用户名都可以这么做：让表1中的follower充当表2的user，表1中的user充当表2中的follower。这样可以把所有互相关注的user找出来。不过结果是成双对出现的，比如1 2 2 1和2 1 1 2都会被收录，但是他们表达的都是user1和user2互相关注，所以最后的count要除以2。</li>
<li>由于两个表字段完全一样，所以内部的SELECT不要写*，否则会出现字段冲突。要么选择其中2个，要么重新命名。</li>
<li>COUNT(a.*)报错，是否count ( * )是唯一正确用法？</li>
</ol>
<h2 id="（3）举一反三"><a href="#（3）举一反三" class="headerlink" title="（3）举一反三"></a>（3）举一反三</h2>]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL-用户向</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL-留存率计算</title>
    <url>/2020/10/27/Sql-%E7%94%A8%E6%88%B7%E7%95%99%E5%AD%98%E7%8E%87%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<p>表名：user_log</p>
<p>字段：device_id, log_time</p>
<p>描述：device_id为用户的设备id（unique），log_time为用户的登陆时间记录</p>
<p><strong>要求：计算某段日期内用户的次日，3日，7日，15日留存率</strong></p>
<a id="more"></a>

<h2 id="（1）sql写法"><a href="#（1）sql写法" class="headerlink" title="（1）sql写法"></a>（1）sql写法</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.first_login_date,</span><br><span class="line">       <span class="keyword">CONCAT</span>(<span class="number">100</span>*<span class="keyword">round</span>(t1<span class="number">.2</span>_day_user/t1.first_day_users,<span class="number">4</span>),<span class="string">&quot;%&quot;</span>) rate_2,</span><br><span class="line">       <span class="keyword">CONCAT</span>(<span class="number">100</span>*<span class="keyword">round</span>(t1<span class="number">.3</span>_user/t1.first_day_users,<span class="number">4</span>),<span class="string">&quot;%&quot;</span>) rate_3,</span><br><span class="line">       <span class="keyword">CONCAT</span>(<span class="number">100</span>*<span class="keyword">round</span>(t1<span class="number">.7</span>_user/t1.first_day_users,<span class="number">4</span>),<span class="string">&quot;%&quot;</span>) rate_7,</span><br><span class="line">       <span class="keyword">CONCAT</span>(<span class="number">100</span>*<span class="keyword">round</span>(t1<span class="number">.15</span>_day_user/t1.first_day_users,<span class="number">4</span>),<span class="string">&quot;%&quot;</span>) rate_15,</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> a.first_login_date, </span><br><span class="line">       <span class="keyword">COUNT</span>(<span class="keyword">distinct</span> a.device_id) first_day_users,</span><br><span class="line">       <span class="keyword">COUNT</span>(<span class="keyword">distinct</span> b.device_id) <span class="number">2</span>_day_users,</span><br><span class="line">       <span class="keyword">COUNT</span>(<span class="keyword">distinct</span> c.device_id) <span class="number">3</span>_day_users,</span><br><span class="line">       <span class="keyword">COUNT</span>(<span class="keyword">distinct</span> d.device_id) <span class="number">7</span>_day_users,</span><br><span class="line">       <span class="keyword">COUNT</span>(<span class="keyword">distinct</span> e.device_id) <span class="number">15</span>_day_users</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> device_id, <span class="keyword">min</span>(log_time) first_login_date</span><br><span class="line"><span class="keyword">FROM</span> user_log</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> device_id) a </span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span></span><br><span class="line">user_log b <span class="keyword">ON</span> a.device_id = b.device_id <span class="keyword">AND</span> DATADIFF(b.log_time, a.first_login_date)=<span class="number">1</span></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span></span><br><span class="line">user_log c <span class="keyword">ON</span> a.device_id = c.device_id <span class="keyword">AND</span> DATADIFF(c.log_time, a.first_login_date)=<span class="number">2</span></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span></span><br><span class="line">user_log d <span class="keyword">ON</span> a.device_id = d.device_id <span class="keyword">AND</span> DATADIFF(d.log_time, a.first_login_date)=<span class="number">6</span></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span></span><br><span class="line">user_log e <span class="keyword">ON</span> a.device_id = e.device_id <span class="keyword">AND</span> DATADIFF(e.log_time, a.first_login_date)=<span class="number">14</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.first_login_date) t1</span><br></pre></td></tr></table></figure>

<h2 id="（2）思路及注意事项"><a href="#（2）思路及注意事项" class="headerlink" title="（2）思路及注意事项"></a>（2）思路及注意事项</h2><ol>
<li>首先要求出每个用户第一次登录的时间，并以此表作为基础，左联其他表格。</li>
<li>求留存时按照first_login_date分组，可以求得不同天的登录用户数。</li>
<li>常用函数DATEDIFF, ROUND, CONCAT的用法</li>
</ol>
<h2 id="（3）举一反三"><a href="#（3）举一反三" class="headerlink" title="（3）举一反三"></a>（3）举一反三</h2>]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL-用户向</tag>
      </tags>
  </entry>
  <entry>
    <title>Python</title>
    <url>/2020/10/27/%E6%B6%88%E9%99%A4%E8%AD%A6%E5%91%8A%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<p>本文记录了使用SKlearn进行机器学习过程中遇到的一些问题，包括数据可视化及数据预处理。</p>
<a id="more"></a>

<h2 id="1-消除警告信息"><a href="#1-消除警告信息" class="headerlink" title="1.消除警告信息"></a>1.消除警告信息</h2><p>python开发中经常遇到报错的情况，但是warning通常并不影响程序的运行，而且有时特别讨厌，该语句主要用来忽略warning错误。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="2-更改图标显示风格，非必要"><a href="#2-更改图标显示风格，非必要" class="headerlink" title="2.更改图标显示风格，非必要"></a>2.更改图标显示风格，非必要</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-sklearn的转换器和分类器"><a href="#3-sklearn的转换器和分类器" class="headerlink" title="3.sklearn的转换器和分类器"></a>3.<strong>sklearn的转换器和分类器</strong></h2><h3 id="1-BaseEstimator"><a href="#1-BaseEstimator" class="headerlink" title="(1)BaseEstimator:"></a>(1)BaseEstimator:</h3><p>基础分类器的类（Base class for all estimators in scikit-learn）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InductiveClusterer</span>(<span class="params">BaseEstimator</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, clusterer, classifier</span>):</span></span><br><span class="line">        self.clusterer = clusterer</span><br><span class="line">        self.classifier = classifier</span><br><span class="line"><span class="comment">#这里表示新建一个派生类InductiveClusterer,它继承了基类BaseEstimator</span></span><br></pre></td></tr></table></figure>

<p><strong>名称 BaseClassName 必须定义于包含派生类定义的作用域中</strong>。也允许用其他任意表达式代替基类名称所在的位置。 这有时也可能会用得上，例如，当基类定义在另一个模块中的时候:</p>
<p><strong>class DerivedClassName(modname.BaseClassName):</strong></p>
<h3 id="2-其他分类器和转换器"><a href="#2-其他分类器和转换器" class="headerlink" title="(2)其他分类器和转换器"></a>(2)其他分类器和转换器</h3><p>ClassifierMixin是基础转换器, RegressorMixin基础回归器,TransformerMixin是基础转换器。</p>
<p>RegressorMixin和ClassifierMixin里只有Score方法，没有fit方法，需要自己写到mixin里去实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin, RegressorMixin, clone</span><br></pre></td></tr></table></figure>

<h2 id="4-RobustScaler与StandardScaler的区别"><a href="#4-RobustScaler与StandardScaler的区别" class="headerlink" title="4.RobustScaler与StandardScaler的区别"></a>4.RobustScaler与StandardScaler的区别</h2><p>StandardScaler可以将数据中心化，具体的操作是将数据减去均值后除以标准差。</p>
<p>而对于有离群点，尤其是outliers比较多的情况，使用均值和标准差方式标准化效果不好，这种时候考虑用RobustScaler。具体的方法是移除中位数并根据IQR范围对数据缩放（IQR:在1分位数和3分位数之间）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler, StandardScaler</span><br></pre></td></tr></table></figure>

<h2 id="5-引入均方误差"><a href="#5-引入均方误差" class="headerlink" title="5.引入均方误差"></a>5.引入均方误差</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">y_true = [<span class="number">3.0</span>, <span class="number">-0.5</span>, <span class="number">2</span>, <span class="number">7</span>]</span><br><span class="line">y_pred = [<span class="number">2.5</span>,  <span class="number">0.0</span>, <span class="number">2</span>, <span class="number">8</span>]</span><br><span class="line">mean_squred_error(y_true,y_min) <span class="comment">#0.375</span></span><br><span class="line">mean_squred_error(y_true,y_min,squared=<span class="literal">False</span>) <span class="comment">#0.612</span></span><br><span class="line"><span class="comment">#squred: If True returns MSE value, if False returns RMSE value.</span></span><br></pre></td></tr></table></figure>

<h2 id="6-pipeline和make-pipeline"><a href="#6-pipeline和make-pipeline" class="headerlink" title="6.pipeline和make_pipeline"></a>6.pipeline和make_pipeline</h2><p>pipeline是你给steps命名，而make_pipeline是根据方法自动命名steps。</p>
<p>The only difference is that <code>make_pipeline</code> generates names for steps automatically.</p>
<p>Step names are needed e.g. if you want to use a pipeline with model selection utilities (e.g. GridSearchCV). With grid search you need to specify parameters for various steps of a pipeline:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">pipe = Pipeline([(<span class="string">&#x27;vec&#x27;</span>, CountVectorizer()), (<span class="string">&#x27;clf&#x27;</span>, LogisticRegression()])</span><br><span class="line">param_grid = [&#123;<span class="string">&#x27;clf__C&#x27;</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]&#125;</span><br><span class="line">gs = GridSearchCV(pipe, param_grid)</span><br><span class="line">gs.fit(X, y)</span><br></pre></td></tr></table></figure>

<p>compare it with make_pipeline:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">pipe = make_pipeline(CountVectorizer(), LogisticRegression())     </span><br><span class="line">param_grid = [&#123;<span class="string">&#x27;logisticregression__C&#x27;</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]&#125;</span><br><span class="line">gs = GridSearchCV(pipe, param_grid)</span><br><span class="line">gs.fit(X, y)</span><br></pre></td></tr></table></figure>

<p>So, with <code>Pipeline</code>:</p>
<ul>
<li>names are explicit, you don’t have to figure them out if you need them;</li>
<li><strong>name doesn’t change if you change estimator/transformer used in a step, e.g. if you replace LogisticRegression() with LinearSVC() you can still use <code>clf__C</code>.</strong></li>
</ul>
<p><code>make_pipeline</code>:</p>
<ul>
<li>shorter and arguably more readable notation;</li>
<li>names are auto-generated using a straightforward rule (lowercase name of an estimator).</li>
</ul>
<p>When to use them is up to you :) I prefer make_pipeline for quick experiments and Pipeline for more stable code; a rule of thumb: IPython Notebook -&gt; make_pipeline; Python module in a larger project -&gt; Pipeline. But it is certainly not a big deal to use make_pipeline in a module or Pipeline in a short script or a notebook.</p>
<h3 id="7-克隆estimator"><a href="#7-克隆estimator" class="headerlink" title="7.克隆estimator"></a>7.克隆estimator</h3><p>Constructs a new estimator with the same parameters.</p>
<p>Clone does a deep copy of the model in an estimator without actually copying attached data. It yields a new estimator with the same parameters that has not been fit on any data.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sklearn.base.clone(estimator, *, safe=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="8-sklearn-impute-SimpleImputer"><a href="#8-sklearn-impute-SimpleImputer" class="headerlink" title="8.sklearn.impute.SimpleImputer"></a>8.sklearn.impute.SimpleImputer</h3><p>用来填补缺失值（missing_valules），采取strategy策略，注意strategy一般都应用在各列（column）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">impute</span>.<span class="title">SimpleImputer</span>(<span class="params">*, missing_values=nan, strategy=<span class="string">&#x27;mean&#x27;</span>, fill_value=<span class="literal">None</span>, verbose=<span class="number">0</span>, copy=<span class="literal">True</span>, add_indicator=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp_mean = SimpleImputer(missing_values=np.nan, strategy=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp_mean.fit([[<span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, np.nan, <span class="number">3</span>], [<span class="number">10</span>, <span class="number">3</span>, np.nan]])</span><br><span class="line">SimpleImputer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[np.nan, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, np.nan, <span class="number">5</span>], [<span class="number">1</span>,<span class="number">4</span>,np.nan]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(imp_mean.transform(X))</span><br><span class="line">array([[<span class="number">6.33333333</span>, <span class="number">2.</span>        , <span class="number">3.</span>        ],</span><br><span class="line">       [<span class="number">2.</span>        , <span class="number">2.5</span>       , <span class="number">5.</span>        ],</span><br><span class="line">       [<span class="number">1.</span>        , <span class="number">4.</span>        , <span class="number">3.</span>        ]])</span><br><span class="line"><span class="comment">#注意是拿第一个数组fit后的参数去填充第二个数组的missing_values.</span></span><br></pre></td></tr></table></figure>

<h3 id="9-scipy-stats库"><a href="#9-scipy-stats库" class="headerlink" title="9.scipy_stats库"></a>9.scipy_stats库</h3><p>主要包含了一些统计学上的特征值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> skew</span><br></pre></td></tr></table></figure>

<h3 id="10-pandas中的transform和apply函数"><a href="#10-pandas中的transform和apply函数" class="headerlink" title="10.pandas中的transform和apply函数"></a>10.pandas中的transform和apply函数</h3><p><a href="https://zhuanlan.zhihu.com/p/86350553">https://zhuanlan.zhihu.com/p/86350553</a></p>
<h3 id="11-map函数"><a href="#11-map函数" class="headerlink" title="11.map函数"></a>11.map函数</h3><p>注意DataFrame和Series的map函数和python内置的有些不同。</p>
<h3 id="12-select-dtypes函数"><a href="#12-select-dtypes函数" class="headerlink" title="12.select_dtypes函数"></a>12.select_dtypes函数</h3><p>一个dataframe中可能有多种类型的数据，select_dtypes用于选择某种特定类型的数据。</p>
<p>include:包含该类型的都要，exclude:除了该类型的都要。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DataFrame.select_dtypes(include = <span class="literal">None</span>, exclude = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>罗格斯特征数</title>
    <url>/2020/10/27/%E7%BD%97%E6%A0%BC%E6%96%AF%E7%89%B9%E5%BE%81%E6%95%B0/</url>
    <content><![CDATA[<p>现第一行有0 1 2 3 4 5 6 7 8 9这10个数字。</p>
<p>在第二行这10个数字下方以如下方法填入新的数字：每个位置填入的数字是上方对应的数字将要在第二行出现的次数。</p>
<a id="more"></a>

<table>
<thead>
<tr>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
<th align="center">8</th>
<th align="center">9</th>
</tr>
</thead>
<tbody><tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>思路： 判断哪个数字应该出现的次数最多</p>
]]></content>
      <categories>
        <category>概率论</category>
      </categories>
      <tags>
        <tag>概率趣味题</tag>
      </tags>
  </entry>
</search>
